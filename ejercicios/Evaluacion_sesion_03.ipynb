{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e1cc97-a123-41da-9257-8a8790ddfc43",
   "metadata": {},
   "source": [
    "#### Como primera misión el cliente ha solicitado corroborar que dominamos el manejo de transformaciones con RDD's. Presta mucha atención a las instrucciones listadas y resuelve las actividades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db178849-112f-4099-8552-f0fc634edbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaf790-7728-4745-9e49-8d8365460ddf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO: Crear la sesion de spark y el contexto de spark. Almacenarlos en las variables \"spark\" y \"sc\" respectivamente. \n",
    "##### Colocando \"local[*]\" en la opción master y \"ejercicio_3\" en el appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27877c4d-c5c1-4a5f-ba76-4673e37aba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ejercicio_3\" ) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate() # crear contexto de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bed029-3e52-49e1-8daa-b7657637309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "assert type(spark) == SparkSession\n",
    "assert spark.sparkContext.getConf().get(\"spark.master\") == \"local[*]\"\n",
    "assert spark.sparkContext.getConf().get(\"spark.app.name\") == \"ejercicio_3\"\n",
    "assert type(sc) == SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388701b-4c36-48cd-854e-67b3af2f30e3",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO: Leer el archivo de texto: \"../resources/data/txt/green_eggs_and_ham.txt\" utilizando el sparkContext para cargar un RDD[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fb2645-b61a-4d41-9735-8f289b8a8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "##data=sc.textFile(\"../resources/data/txt/green_eggs_and_ham.txt\")\n",
    "data: RDD = sc.textFile(\"../resources/data/txt/green_eggs_and_ham.txt\") #... reemplazar por lectura de archivo con sc\n",
    "\n",
    "data.foreach(lambda item: print(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879865f3-adc2-4d53-ac3f-e2c72c19fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "assert type(data) == RDD\n",
    "assert data.count() == 103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013873e-3449-4967-8fae-242ef6247212",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO: Crear un RDD que contenga el conteo de cada palabra contenida en el documento leido anteriormente.\n",
    "##### El resultado tendrá que ser un RDD de tuplas con la siguiente estructura (word, count), donde la primer posición deberá ser la palabra y la segunda posicion el total de veces que aparece esa palabra en el RDD leido \n",
    "##### NOTA: Limpiar el contenido de data ya que existen espacios dobles y convertir todo el contenido en MAYUSCULAS\n",
    "Ejemplo:\n",
    "\n",
    "Archivo de entrada:\n",
    "\n",
    "HOLA  MUNDO HOLA  \n",
    "feliZ Mundo  \n",
    "FELIZ MUNDO ADIOS\n",
    "\n",
    "Salida:\n",
    "\n",
    "(MUNDO, 3)  \n",
    "(HOLA, 2)  \n",
    "(FELIZ, 2)  \n",
    "(ADIOS, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29788924-a28f-44d2-a875-f6de87fae89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "# reemplazar por transformaciones a la variable data\n",
    "result: RDD = data.flatMap(lambda item:item.split())\\\n",
    ".map(lambda word: (word.upper(), 1))\\\n",
    ".reduceByKey(lambda a,b: a + b) \n",
    "#Se uso Map para las mayusculas con upper y reducebykey como contador de las palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8daf2f69-0f83-4703-8444-05469946f225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "016a94dc-7df0-41ab-a667-8890c85b9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "assert result.count() == 52\n",
    "\n",
    "ordered_result = result.sortBy(lambda item: item[1], ascending=False, numPartitions=1).take(5)\n",
    "expected = [('I', 83), ('NOT', 82), ('THEM', 58), ('A', 56), ('LIKE', 44)]\n",
    "assert ordered_result == expected\n",
    "\n",
    "sam_values = result.filter(lambda item: item[0] == 'SAM').take(1)\n",
    "assert sam_values[0][1] == 19\n",
    "result.foreach(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0fae4-cb5a-4946-8d75-a0448e325484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
